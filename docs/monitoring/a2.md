Заметка написана специально для коммунити [VictoriaMetrics_ru1](https://t.me/VictoriaMetrics_ru1) в телеграм.

## Выбор tsdb

В vmware vcenter можно посмотреть realtime метрики виртуальных машин, которые хранятся с момента включения или миграции
виртуальной машины в течение одного часа. Есть еще исторические данные в отдельной базе. Туда они пишутся в соотв. с настройками
[Data Collection Levels](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.vcenter.configuration.doc/GUID-25800DE4-68E5-41CC-82D9-8811E27924BC.html).
Изменение уровня логирования и изменение интервалов приведет к росту базы, деградации производительности. Благо есть api, используя который
можно получить значения нужных счетчиков производительности и сохранить их в отдельную базу для дальшейшего использования.

Чем можно опрашивать vcenter:

* telegraf с input плагином [vsphere](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/vsphere);
* [vmware_exporter](https://github.com/pryorda/vmware_exporter);
* [govc_exporter](https://github.com/Intrinsec/govc_exporter).

Про последний нужно только знать, что коммунити prometheus не приветствует разработку нескольких экспортеров для одного
и того же софта, поэтому в свое время автор был послан разработчиком дорабатывать экспортер на python,
а не предлагать свое ПО. В итоге автор забил.

Куда можно писать данные:

* В influxdb только telegraf'ом;
* В prometheus только опрашивая exporter'ы;
* В victoriametrics всем чем угодно, т.к. и база, и vmagent поддерживает оба формата: prometheus и influx.
Но кроме текстовых значений. Например, ip-адреса записать не получится.

Будет использоваться и telegraf, и vmware_exporter одновременно. В итоге все данные будут сохраняться в victoriametrics.
Нужно не забывать про эту особенность:

> Note that InfluxDB line protocol expects timestamps in nanoseconds by default, while VictoriaMetrics stores them with milliseconds precision.

Краткое сравнение экспортера (VE) и плагина телеграфа (TG) ниже.

### Лейблы и теги

TG: в метриках нет данных о гипервизоре, датасторе. Только о кластере и это **правильно** с точки зрения хранения данных в tsdb,
потому что временной ряд не должен прерываться из-за миграции виртуальной машины на другой гипервизор или датастор. Идеально и неожиданно.

VE: Много лишнего, но это может быть полезным. Например, посмотреть когда куда мигрировала виртуальная машина.

### Счетчики

TG: Указываются в конфигурационном файле, опрашиваются все указанные.

VE: Указываются в коде (wat?).
Пишутся только суммарные значения и нет данных по конкретному ядру, сетевому интерфейсу.
Не получается настроить сохранение счетчиков IOPS'ов. Опрос есть, а результата нет. По виртуальным машинам сохраняются из коробки дополнительные счетчики по кол-ву
vcpu, снапшотам, данным из гостевой ОС. При запущенном в vcenter'е процессе клонирования счетчики опросятся, но преобразовать в метрики exporter их не может из-за ошибки.
Тоже самое происходит когда недоступен какой-то из гипервизоров. Все долго и плохо.

## Сustom-атрибуты

TG: Если атрибут есть и он пустой, то тега с ним не будет.

VE: Если атрибут есть и он пустой, то будет тег со значением `n/a`.

### Установка

TG: Бинарник с понятными конфигурационным файлами.

VE: pip или docker с примером конфигурации из readme

## Счетчики производительности

Через UI в vcenter можно смотреть разные графики по разным счетчикам. Иной раз непонятно какой именно нужно опрашивать.
Для этого есть [govmomi](https://github.com/vmware/govmomi).

```sh
cd /tmp
wget https://github.com/vmware/govmomi/releases/download/v0.27.2/govc_Linux_x86_64.tar.gz
tar zxvf govc_Linux_x86_64.tar.gz
```
Нужны переменные для подлкючения к vcenter

```sh
export GOVC_USERNAME=vmuser
export GOVC_PASSWORD=pswd
export GOVC_URL=vcenter-host
export GOVC_INSECURE=true
```
Для настройки telegraf'а потребуется указать корректный интервал. Если он не менялся, то это 5m.

```sh
./govc metric.interval.info
```
вывод
```text
ID:                   300
  Enabled:            true
  Interval:           5m
  Available Samples:  288
  Name:               Past day
  Level:              1
ID:                   1800
  Enabled:            true
  Interval:           30m
  Available Samples:  336
  Name:               Past week
  Level:              1
ID:                   7200
  Enabled:            true
  Interval:           2h
  Available Samples:  360
  Name:               Past month
  Level:              1
ID:                   86400
  Enabled:            true
  Interval:           24h
  Available Samples:  365
  Name:               Past year
  Level:              1
```
Список доступных метрик
```sh
 ./govc metric.ls /*/vm/* > vm.out
```
Просмотр информации по конкретному счетчику
```sh
./govc metric.info - cpu.usage.average
```
вывод как из документации практически
```text
Name:                cpu.usage.average
  Label:             Usage
  Summary:           CPU usage as a percentage during the interval
  Group:             CPU
  Unit:              %
  Rollup type:       average
  Stats type:        rate
  Level:             1
    Intervals:       Past day,Past week,Past month,Past year
  Per-device level:  3
    Intervals:
```

## victoriametrics

Предполагается, что база и vmagent установлены и запущены. Неважно кластер или сингл.
Агент устанавливается на хост(ы) с vmware_exporter'ом, telegraf'ом,
чтобы при недоступности базы сохранить полученные метрики в очереди на локальном диске.
Тут необходимо определиться с интервалом и решить как часто будут записываться любые метрики в базу.
Пусть 1m. Тогда минимальный конфиг для vmagent'а, установленного на exporters-host такой:
```yaml
global:
  scrape_interval: 60s
  scrape_timeout: 30s

scrape_configs:
  - job_name: vmagent
    static_configs:
    - targets:
      - exporters-host:8429
  - job_name: victoria-metrics
    static_configs:
    - targets:
      - victoriametrics-host:8428
```
vmagent можно запускать с флагами или указать брать параметры из переменных.
Для второго варианта /etc/default/vmagent выглядит так:
```text
#
# Ansible managed
#

# must have
VMAGENT_promscrape_config=/etc/vmagent/vmagent.yml
VMAGENT_remoteWrite_tmpDataPath=/var/lib/vmagent
VMAGENT_remoteWrite_url='http://victoriametrics-host:8428/api/v1/write'

# optional
VMAGENT_promscrape_suppressScrapeErrors=True
VMAGENT_influxTrimTimestamp=1s
VMAGENT_remoteWrite_urlRelabelConfig='/etc/vmagent/relabel/telegraf.yml'
```
Запуск из /lib/systemd/system/vmagent.service
```text
#
# Ansible managed
#

[Unit]
Description=Victoria-metrics vmagent
After=network-online.target auditd.service

[Service]
Type=simple
User=vmagent
Group=vmagent
EnvironmentFile=-/etc/default/vmagent
ExecReload=/bin/kill -HUP $MAINPID
ExecStart=/usr/local/bin/vmagent -envflag.enable -envflag.prefix=VMAGENT_

SyslogIdentifier=vmagent
Restart=always
LimitNOFILE=infinity
ReadWriteDirectories=/var/lib/vmagent

PrivateTmp=yes
ProtectHome=yes
NoNewPrivileges=yes
ProtectSystem=strict
ProtectControlGroups=true
ProtectKernelModules=true
ProtectKernelTunables=yes

[Install]
WantedBy=multi-user.target
```

## vmware_exporter

Установка в пользовательском окружении
```sh
pip install vmware_exporter
```
Запуск
```sh
vmware_exporter -c config.yml
```
Конфиг без опроса хостов и датасторов. Для них можно указать отдельную конфигурацию и опрашивать отдельным job'ом.
```yaml
default:
    vsphere_host: "vcenter-host"
    vsphere_user: "vmuser"
    vsphere_password: "pswd"
    ignore_ssl: True
    specs_size: 5000
    fetch_custom_attributes: True
    fetch_tags: False
    fetch_alarms: False
    collect_only:
        vms: True
        vmguests: True
        datastores: False
        hosts: False
        snapshots: True
```
При старте напишет порт, куда следует подключиться для проверки
```sh
curl http://localhost:9272/metrics > vc.metrics
```
Добавить job для опроса экспортера в vmagent. Это уже после nice_yaml, поэтому отсортировано и отформатировано вот так.
```yaml
  - job_name: vcenter
    metric_relabel_configs:
    - regex: ^([A-Z]):.*
      replacement: $1
      source_labels:
      - partition
      target_label: partition
    - action: drop
      regex: /target|/storage/archive
      source_labels:
      - partition
    - action: labeldrop
      regex: host_name|ds_name
    static_configs:
    - targets:
      - exporters-host:9272
```
При опросе экпортера будут применены правила relabel ко всем полученным метрикам, а именно:

* из названия разделов дисков ОС windows будут удаляться двоеточия, иначе их придется экранировать в запросах;
* будут удаляться все метрики с разделами в ОС linux `/target` или `/storage/archive`, собирать которые бессмысленно;
* удалить лейблы `host_name` и `ds_name` чтобы уменьшить количество временных рядов или т.н. [churn rate](https://docs.victoriametrics.com/FAQ.html#what-is-high-churn-rate).

## telegraf

Установка пакета при условии что репа добавлена
```sh
apt install telegraf
```
В другой заметке писал почему нужно для разных устройств делать разные конфиги в /etc/telegraf/telegraf.d. Не буду повторяться.
Нужно создать какой-то конфигурационный файл без лишних строк
```sh
telegraf --input-filter vsphere --output-filter influxdb config | grep -v '#' | grep -v '^$' > influx
```
Далее внести изменения с учетом того что timestamp будет округляться до секунд в `precision`, интервал 1m, а секцию с inputs вынести в отдельный файл.
В итоге /etc/telegraf/telegraf.conf будет выглядеть так и писать vmagent'у в порт 8429.
```toml
[global_tags]
[agent]
  interval = "1m"
  round_interval = false
  metric_batch_size = 1000
  metric_buffer_limit = 100000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = "s"
  hostname = ""
  omit_hostname = true
[[outputs.influxdb]]
  urls = ["http://127.0.0.1:8429"]
  exclude_database_tag = true
  skip_database_creation = true
```
Тег `hostname` не нужен, а тег `db` будет удален vmagent'ом relabel правилами из `/etc/vmagent/relabel/telegraf.yml` до записи в базу.

Плагин vsphere c конфигурацией по умолчанию опрашивает много данных.
Нужно сделать один конфигурационный файл для быстрого опроса счетчиков виртуальных машин, а если требуются счетчики по кластеру, хостам, то для них сделать
отдельные конфигурационные файлы и пусть запросы выполняются параллельно. Файл `/etc/telegraf/telegraf.d/vcenter_vm.conf`
```toml
[[inputs.vsphere]]
  vcenters = [ "https://vcenter-host/sdk" ]
  username = "vmuser"
  password = "pswd"
  tagexclude = [ "dcname", "source", "vcenter", "uuid", "moid" ]
  vm_metric_include = [
    "cpu.costop.summation",
    "cpu.ready.summation",
    "cpu.wait.summation",
    "cpu.run.summation",
    "cpu.idle.summation",
    "cpu.used.summation",
    "cpu.demand.average",
    "cpu.usagemhz.average",
    "cpu.usage.average",
    "mem.active.average",
    "mem.granted.average",
    "mem.consumed.average",
    "mem.usage.average",
    "mem.vmmemctl.average",
    "net.bytesRx.average",
    "net.bytesTx.average",
    "net.droppedRx.summation",
    "net.droppedTx.summation",
    "net.usage.average",
    "power.power.average",
    "virtualDisk.numberReadAveraged.average",
    "virtualDisk.numberWriteAveraged.average",
    "virtualDisk.read.average",
    "virtualDisk.readOIO.latest",
    "virtualDisk.throughput.usage.average",
    "virtualDisk.totalReadLatency.average",
    "virtualDisk.totalWriteLatency.average",
    "virtualDisk.write.average",
    "virtualDisk.writeOIO.latest",
    "sys.uptime.latest",
  ]
  host_include = []
  host_exclude = ["*"]
  cluster_include = []
  cluster_exclude = ["*"]
  datastore_include = []
  datastore_exclude = ["*"]
  datacenter_include = []
  datacenter_exclude = ["*"]
  separator = "_"
  collect_concurrency = 10
  discover_concurrency = 10
  custom_attribute_include = ["*"]
  custom_attribute_exclude = []
  insecure_skip_verify = true
  historical_interval = "5m"

[inputs.vsphere.tags]
 job = "vmware_vm"
```
На каждый inputs плагин/файл будет отдельный тег `job` по аналогии с другими exporter'ами.
Конкретно тут `job = "vmware_vm"` будет добавлен к каждой метрике. Из каждой метрики будут удалены теги,
перечисленные в `tagexclude`. `historical_interval` по умолчанию 5m и совпадает с интервалом из `metric.interval.info`.
Все custom-атрибуты, если таковые есть, будут использоваться в качестве тегов.

Проверка
```sh
 telegraf --config /etc/telegraf/telegraf.d/vcenter_vm.conf --test > /tmp/vcenter_vm.out
```
После установки telegraf запущен и работает с конфигурационным файлом по умолчанию.
До перезапуска необходимо настроить relabel конфиг `/etc/vmagent/relabel/telegraf.yml`
```yaml
---
# rename label
- action: labelmap_all
  regex: "vmname"
  replacement: "vm_name"
# remove labels
- action: labeldrop
  regex:
    - "db"
```
Переименован `vmname` чтобы совпадал с vmware_exporter и можно было бы делать запросы по одинаковым лейблам.
Удален лейбл `db`, который пишет telegraf. 

## VMUI

vmagent раз в минуту опрашивает vmware_exporter и принимает от telegraf'а метрики по influx-протоколу.
Зайти на http://victoriametrics-host:8428/vmui/ в instant query table и поделать запросы, посмотреть что насобирал telegraf
```text
max({job="vmware_vm"}) by  (__name__)
```
и что насобирал vmware_exporter
```text
max({job="vcenter"}) by  (__name__)
```

## Grafana

Установить grafana, добавить datasource `Prometheus` c url `http://victoriametrics-host:8428`, создать или добавить готовые дашборды.
Дашборды для influx придется переделать полностью.

## Kapacitor

Не нужен.

## Vmalert

Для метрик из vmware_exporter можно создать разные правила, например:
```yaml
---
groups:
  - name: vmware
    rules:
      - alert: VMMemoryBalooning
        expr: vmware_vm_mem_vmmemctl_average > 0
        for: 1h
        labels:
          severity: info
        annotations:
          summary: "Balooning {{ $labels.vm_name }}"
      - alert: VMDiskLowSpace
        expr: vmware_vm_guest_disk_free{partition="C"} < 10000000000
        for: 5m
        labels:
          severity: warning
          partition: C
        annotations:
          summary: 'Low disk space {{ $labels.partition }} {{ $labels.vm_name }}'
```
Еще можно [тут](https://github.com/pryorda/vmware_exporter/blob/main/alerts/vmware.rules.yml) посмотреть варианты.
Для метрик из telegraf'а можно сделать аналогичные правила.
